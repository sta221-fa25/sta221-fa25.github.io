---
title: "Homework 04: logistic regression"
subtitle: "Due Thursday November 20 at 5:00pm"
format: html
bibliography: references.bib
embed-resources: true
---

```{r}
#| message: false
#| warning: false
library(tidyverse)
```


\newcommand{\bbeta}{\boldsymbol{\beta}}
\newcommand{\by}{\boldsymbol{y}}
\newcommand{\hby}{\hat{\boldsymbol{y}}}
\newcommand{\bone}{\boldsymbol{1}}
\newcommand{\bx}{\boldsymbol{x}}
\newcommand{\bX}{\boldsymbol{X}}
\newcommand{\be}{\boldsymbol{\varepsilon}}
\newcommand{\hbe}{\hat{\be}}
\newcommand{\bA}{\boldsymbol{A}}
\newcommand{\bzero}{\boldsymbol{0}}
\newcommand{\identity}{\boldsymbol{I}}
\newcommand{\hatMatrix}{\boldsymbol{H}}
\newcommand{\bp}{\boldsymbol{p}}

# Conceptual exercises

The conceptual exercises are focused on explaining concepts and showing results mathematically. Show your work for each question.

You may write the answers and associated work for conceptual exercises by hand or type them in a Quarto document.

## Exercise 1[^1]

*Logistic regression interpretation*

[^1]: Exercise adapted from an exercise in *Categorical Data Analysis* by Agresti.

<!--# from categorical data analysis number 5.29 (pg. 204)-->

@berry2001statistician examined the effect of a player's draft position among the pool of potential players in a given year to the probability on eventually being named an all star.

Let $d$ be the draft position $(d = 1, 2, 3, \ldots)$ and $\pi$ be the probability of eventually being named an all star. The researcher modeled the relationship between $d$ and $\pi$ using the following model:

$$
\log\Big(\frac{\pi_i}{1-\pi_i}\Big) = \beta_0 + \beta_1 \log d_i
$$

a.  Using this model, show that the odds of being named an all star are $e^{\beta_0}d^{\beta_1}$ . Then, show how to calculate $\pi_i$ based on this model.

b. What are the odds of being named an all star for the first draft pick?

c.  In the study, Berry reported that for professional basketball $\hat{\beta}_0 = 2.3$ and $\hat{\beta}_1 = -1.1$, and for professional baseball $\hat{\beta}_0 = 0.7$ and $\hat{\beta}_1 = -0.6$ . Explain why this suggests that (1) being a first draft pick is more crucial for being an all star in basketball than in baseball and (2) players picked in high draft positions are relatively less likely to be all stars.

## Exercise 2

*Logistic regression with logit link log-likelihood* 

Show that the **log-likelihood** in a standard logistic regression with a logistic link function can be written

$$
\mathcal{l}(\beta) = \sum_{i=1}^n y_i x_i^T \beta  - \sum_{i=1}^n \log (1 + \exp\{x_i^T\beta\})
$$
Include a (brief) explanation of each step in your derivation.

## Exercise 3

*Score function*

Show that the score function, i.e. the gradient $\frac{\partial}{\partial{\beta}} \mathcal{l}(\beta)$ can be written in matrix form

$$
\bX^T \by - \bX^T \bp,
$$
where $\bp = [p_1, \ldots, p_n]^T$.
Note: you can use the gradient of the log-likelihood in class a starting point and just explain why the representation above makes sense.

## Exercise 4 

*Hessian*

Show that the Hessian matrix, i.e. the matrix of second derivatives, $\frac{\partial^2}{\partial{\beta} \partial{\beta}^T} \mathcal{l}(\beta)$ can be written as 

$$
-\bX^T D \bX
$$
where $D$ is a diagonal matrix with entries $d_{ii} = p_i(1-p_i)$.

## Exercise 5 

*Maximum likelihood estimator*

Show that the maximum likelihood estimator of the logistic regression model with logit link can be written as 

$$
\hat{\beta}_{MLE} = \left( 
\bX^T D \bX
\right)^{-1}
\bX^T D \by ^*
$$ 
where 

$$
\by^* = \bX \hat{\beta}_{MLE} + D^{-1} (\by - \bp).
$$
Hint: multiply out the equation.

## Exercise 6

*How does `glm` find the MLE? Answer: iteratively re-weighted least squares (IRLS)*

Newton-Raphson is a "root finding" algorithm. This means it finds where a function equals zero. We use it to find $\hat{\beta}_{MLE}$. This works because the maximum likelihood estimator will be precisely where the score function equals zero. 

The Newton-Raphson algorithm works to find the MLE as follows:

```
1. Choose a starting point, beta_0
2. Let beta_next = beta_old - H^-1(beta_old) * Score(beta_old)
3. Repeat step 2 until Score(beta_next) is close to 0.
```

Above, `H^-1(beta_old)` denotes the inverse of the Hessian of the log-likelihood evaluated at `beta_old` and `Score(beta_old)` denotes the score function evaluated at `beta_old`.

In logistic regression with a logit link, the update can be written:

$$
\beta_{n+1} = \beta_n + (\bX^TD\bX)^{-1} \left(\bX^T \by - \bX^T \bp \right)
$$

Note: $D$ is a function of $\bp$ which is a function of $\beta$.

(a). Multiply both sides by the negative of the Hessian matrix.

(b). Write the update in terms of $\by^*$, where $\by^* = \bX \hat{\beta}_{n} + D^{-1} (\by - \bp)$.

(c). Solve for $\hat{\beta}_{n+1}$. 

(d). Explain (in words) how this is an iterative generalized (weighted) least squares problem. 

# Applied problems

The applied exercises are focused on applying the concepts to analyze data.

**All work for the applied exercises must be typed in your Quarto document following a reproducible workflow.**

Write all narrative using complete sentences and include informative axis labels / titles on visualizations.

The applied problems will use the data set below. The data were sourced from [kaggle](https://www.kaggle.com/datasets/aavigan/cleveland-clinic-heart-disease-dataset?resource=download) and the original data was collected by Robert Detrano, M.D., Ph.D of the Cleveland Clinic Foundation. See [here](https://www.ahajournals.org/doi/pdf/10.1161/01.CIR.69.3.541) for protocol specifics. 

```{r}
heart = read_csv("../data/cleveland_heart.csv")
# heart = read_csv("https://sta221-fa25.github.io/data/cleveland_heart.csv")
```
The response variable is: `chd`: presence of coronary heart disease (1 for presence, 0 for absence).

The other variables in the data set:

- `age`: age in years

- `sex`: 1 = male, 0 = female

- `chol` — serum cholesterol in mg/dl

- `trestbps` — resting blood pressure

- `fbs` — fasting blood sugar > 120 mg/dl (1 = true; 0 = false)

- `thalach` — maximum heart rate achieved


## Exercise 7

```{r}

```




# Submission

::: callout-warning
Remember -- you must turn in a PDF file to the Gradescope page before the submission deadline for full credit.

If you write your responses to conceptual exercises by hand, you will need to combine your written work to the completed PDF for the applied exercises before submitting on Gradescope.

Instructions to combine PDFs:

-   Preview (Mac): [support.apple.com/guide/preview/combine-pdfs-prvw43696/mac](https://support.apple.com/guide/preview/combine-pdfs-prvw43696/mac)

-   Adobe (Mac or PC): [helpx.adobe.com/acrobat/using/merging-files-single-pdf.html](https://helpx.adobe.com/acrobat/using/merging-files-single-pdf.html)

    -   Get free access to Adobe Acrobat as a Duke student: [oit.duke.edu/help/articles/kb0030141/](https://oit.duke.edu/help/articles/kb0030141/)
:::

To submit your assignment:

-   Access Gradescope through the menu on the Canvas website.

-   Click on the assignment, and you'll be prompted to submit it.

-   Mark the pages associated with each exercise. All of the pages of your lab should be associated with at least one question (i.e., should be "checked").
